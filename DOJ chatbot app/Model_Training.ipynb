{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":["ybq3ghWVMjJe","AnrjrKtoMFcN"],"mount_file_id":"1Wc7Z3g51gJf780qNy9rwQCZlGEfqhJhs","authorship_tag":"ABX9TyN57g6LL3J+jUBNZBQtAJsE"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"71a3c7a933e64a32be8e334c05ba2685":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_f974368de7fe4556ac68b7a13c46e77b","IPY_MODEL_1c18262e1cd3465c8c9770be83a9deb5","IPY_MODEL_36f46ca5145e465b8da0e8f47d6c856b"],"layout":"IPY_MODEL_16a610aee2da4042b248503984df34af"}},"f974368de7fe4556ac68b7a13c46e77b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b14bada3eb0b475fb7e974ba4d9812c2","placeholder":"â€‹","style":"IPY_MODEL_710f6f2dbffe4e36a69bf4a3a3b7c2a3","value":"Generatingâ€‡trainâ€‡split:â€‡"}},"1c18262e1cd3465c8c9770be83a9deb5":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_7329008240054a49a2f0a5040a808711","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_f5373dcd3804407e84b7585956da3385","value":1}},"36f46ca5145e465b8da0e8f47d6c856b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5587d37dca1e4dc1b898975357157f2d","placeholder":"â€‹","style":"IPY_MODEL_e972bfa5d84c45f695cefe212d79489c","value":"â€‡120/0â€‡[00:00&lt;00:00,â€‡1392.40â€‡examples/s]"}},"16a610aee2da4042b248503984df34af":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b14bada3eb0b475fb7e974ba4d9812c2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"710f6f2dbffe4e36a69bf4a3a3b7c2a3":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7329008240054a49a2f0a5040a808711":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"f5373dcd3804407e84b7585956da3385":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"5587d37dca1e4dc1b898975357157f2d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e972bfa5d84c45f695cefe212d79489c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a78feee26fb24cf397f732616b53a478":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_35556f0ff7cf4e27bf04bc05ee25ed94","IPY_MODEL_24bb98e7ace948a58d5d6f04ed91f4d3","IPY_MODEL_f74403a2f5944359870cf94d5fb81a69"],"layout":"IPY_MODEL_6b7789af2b6a4fa296e2c0092008f06c"}},"35556f0ff7cf4e27bf04bc05ee25ed94":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_79c88ec4ea8d4a78a8cd347b6bb5ac73","placeholder":"â€‹","style":"IPY_MODEL_3218d09867a4479e9eebb6a6c557f068","value":"model.safetensors:â€‡100%"}},"24bb98e7ace948a58d5d6f04ed91f4d3":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_b86a7fcc774544cf8e7bb17f283dddf4","max":548105171,"min":0,"orientation":"horizontal","style":"IPY_MODEL_bdb5943deb7a4cd7bfc4275556e90064","value":548105171}},"f74403a2f5944359870cf94d5fb81a69":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_502115fbd5d2415bbab4bac6a247186b","placeholder":"â€‹","style":"IPY_MODEL_cd34113e29914259abe56c7ded202d0f","value":"â€‡548M/548Mâ€‡[00:04&lt;00:00,â€‡42.3MB/s]"}},"6b7789af2b6a4fa296e2c0092008f06c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"79c88ec4ea8d4a78a8cd347b6bb5ac73":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3218d09867a4479e9eebb6a6c557f068":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b86a7fcc774544cf8e7bb17f283dddf4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bdb5943deb7a4cd7bfc4275556e90064":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"502115fbd5d2415bbab4bac6a247186b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cd34113e29914259abe56c7ded202d0f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b33dd45adc1f47d199c87bf37e055443":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_ba9ee3a5398b4f1fb32f006032206bff","IPY_MODEL_8394ee1c238e4e6c8ca1679f0ba282be","IPY_MODEL_277f46c117a64e8eb80e1d77eb919cc7"],"layout":"IPY_MODEL_f1cfec47a4bb4f9e8f142b6cb83dfd22"}},"ba9ee3a5398b4f1fb32f006032206bff":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ad4f877b457a4a06a24c0404e5044704","placeholder":"â€‹","style":"IPY_MODEL_2ee1d9cef21e442aba31ff8ed96f6765","value":"generation_config.json:â€‡100%"}},"8394ee1c238e4e6c8ca1679f0ba282be":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_2b0303ceb3504fd39753606fdef3e3fd","max":124,"min":0,"orientation":"horizontal","style":"IPY_MODEL_980f55a408bb4370a1b7f5a49cfa7176","value":124}},"277f46c117a64e8eb80e1d77eb919cc7":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3ebbce0d952b448092b49b5a4f2530f4","placeholder":"â€‹","style":"IPY_MODEL_2e07d84df6bf466bb30e697af3b8bb28","value":"â€‡124/124â€‡[00:00&lt;00:00,â€‡4.05kB/s]"}},"f1cfec47a4bb4f9e8f142b6cb83dfd22":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ad4f877b457a4a06a24c0404e5044704":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2ee1d9cef21e442aba31ff8ed96f6765":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2b0303ceb3504fd39753606fdef3e3fd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"980f55a408bb4370a1b7f5a49cfa7176":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"3ebbce0d952b448092b49b5a4f2530f4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2e07d84df6bf466bb30e697af3b8bb28":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ffee1dc877d544bfa770cc216278a954":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_6855611fa0034a6786cf10653c9342f1","IPY_MODEL_66faec5e902d45fd91a5f69f785bdc62","IPY_MODEL_97647a7d602043ef90893397cf5f4958"],"layout":"IPY_MODEL_0e17e640077b42baaff6dde4e75869b3"}},"6855611fa0034a6786cf10653c9342f1":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_28a70b4462ff497480b2d6ba4a47177e","placeholder":"â€‹","style":"IPY_MODEL_d7a60bbb7efd4f67bcc627e830bc9b59","value":"Map:â€‡100%"}},"66faec5e902d45fd91a5f69f785bdc62":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_bfbaca0730e5418692784cb12c249bf2","max":120,"min":0,"orientation":"horizontal","style":"IPY_MODEL_213097a126a0468580933300c90fac75","value":120}},"97647a7d602043ef90893397cf5f4958":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5d1a6e216d7248b5b9d712b15bc7bbc4","placeholder":"â€‹","style":"IPY_MODEL_5774de2068cf4b31a54275c73326c27b","value":"â€‡120/120â€‡[00:00&lt;00:00,â€‡293.32â€‡examples/s]"}},"0e17e640077b42baaff6dde4e75869b3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"28a70b4462ff497480b2d6ba4a47177e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d7a60bbb7efd4f67bcc627e830bc9b59":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"bfbaca0730e5418692784cb12c249bf2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"213097a126a0468580933300c90fac75":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"5d1a6e216d7248b5b9d712b15bc7bbc4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5774de2068cf4b31a54275c73326c27b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"markdown","source":["# ***FINE TUNING GPT2 ON CUSTOM DATA***"],"metadata":{"id":"fyFeGF83e4Jt"}},{"cell_type":"code","source":["import torch\n","from transformers import GPT2Tokenizer, GPT2LMHeadModel, Trainer, TrainingArguments\n","from datasets import load_dataset\n","\n","# Load the dataset directly\n","dataset = load_dataset(\"text\", data_files=\"/content/drive/MyDrive/Colab Notebooks/SIH- DOJ CHATBOT/Data/dojdataset.txt\", split=\"train\")  # Replace \"your_data.txt\" with your file name\n","\n","# Load tokenizer and model\n","tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n","model = GPT2LMHeadModel.from_pretrained(\"gpt2\")\n","\n","# Add special tokens\n","special_tokens = {\n","    'additional_special_tokens': ['<|startoftext|>', '|bot|', '<|endoftext|>']\n","}\n","tokenizer.add_special_tokens(special_tokens)\n","tokenizer.add_special_tokens({'pad_token': '[PAD]'})\n","model.resize_token_embeddings(len(tokenizer))\n","\n","# Tokenize the data\n","def tokenize_function(examples):\n","    return tokenizer(examples[\"text\"], truncation=True, padding=\"max_length\", max_length=512)\n","\n","tokenized_dataset = dataset.map(tokenize_function, batched=True, remove_columns=[\"text\"])\n","\n","# Data collator for dynamic padding\n","from transformers import DataCollatorForLanguageModeling\n","data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=False)\n","\n","# Training arguments\n","training_args = TrainingArguments(\n","    output_dir=\"/content/drive/MyDrive/Colab Notebooks/SIH- DOJ CHATBOT/Trained LLM model\",\n","    overwrite_output_dir=True,\n","    num_train_epochs=3,\n","    per_device_train_batch_size=4,\n","    save_steps=500,\n","    save_total_limit=2,\n","    logging_dir=\"./logs\",\n","    logging_steps=10,\n","    learning_rate=5e-5,\n","    weight_decay=0.01,\n","    prediction_loss_only=True,\n","    evaluation_strategy=\"no\",\n","    report_to=\"none\"\n",")\n","\n","# Trainer setup\n","trainer = Trainer(\n","    model=model,\n","    args=training_args,\n","    train_dataset=tokenized_dataset,\n","    data_collator=data_collator,\n",")\n","\n","# Fine-tune the model\n","trainer.train()\n","\n","# Save the fine-tuned model\n","model.save_pretrained(\"/content/drive/MyDrive/Colab Notebooks/SIH- DOJ CHATBOT/Trained LLM model\")\n","tokenizer.save_pretrained(\"/content/drive/MyDrive/Colab Notebooks/SIH- DOJ CHATBOT/Trained LLM model\")\n","\n","# Testing the model (optional)\n","def generate_answer(question):\n","    input_text = f\"<|startoftext|> {question} |bot|\"\n","    inputs = tokenizer.encode(input_text, return_tensors=\"pt\")\n","    outputs = model.generate(inputs, max_length=100, pad_token_id=tokenizer.eos_token_id)\n","    response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n","    return response\n","\n","# Example\n","question = \"What are the number of cases registered as of January,2023?\"\n","print(generate_answer(question))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":577},"id":"cyIELHzQfVAQ","executionInfo":{"status":"ok","timestamp":1732462921146,"user_tz":-330,"elapsed":3416934,"user":{"displayName":"Nancy Kaim","userId":"03700283372253325446"}},"outputId":"b26aa7e3-c571-4cc6-d842-c55830550648","collapsed":true},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n","The secret `HF_TOKEN` does not exist in your Colab secrets.\n","To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n","You will be able to reuse this secret in all of your notebooks.\n","Please note that authentication is recommended but still optional to access public models or datasets.\n","  warnings.warn(\n","The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`\n","/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1568: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n","  warnings.warn(\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='99' max='99' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [99/99 55:43, Epoch 3/3]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>10</td>\n","      <td>3.796400</td>\n","    </tr>\n","    <tr>\n","      <td>20</td>\n","      <td>3.237300</td>\n","    </tr>\n","    <tr>\n","      <td>30</td>\n","      <td>2.922200</td>\n","    </tr>\n","    <tr>\n","      <td>40</td>\n","      <td>2.601200</td>\n","    </tr>\n","    <tr>\n","      <td>50</td>\n","      <td>2.298800</td>\n","    </tr>\n","    <tr>\n","      <td>60</td>\n","      <td>2.395900</td>\n","    </tr>\n","    <tr>\n","      <td>70</td>\n","      <td>2.156400</td>\n","    </tr>\n","    <tr>\n","      <td>80</td>\n","      <td>2.095800</td>\n","    </tr>\n","    <tr>\n","      <td>90</td>\n","      <td>1.957300</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"]},{"output_type":"stream","name":"stdout","text":[" What are the number of cases registered as of January,2023?  The number of registered cases is currently at 1,000,000. \n"]}]},{"cell_type":"markdown","source":["# ***TRAINED GPT2 MODEL INFO***"],"metadata":{"id":"ybq3ghWVMjJe"}},{"cell_type":"code","source":["from transformers import GPT2LMHeadModel, GPT2Tokenizer\n","\n","# Path to your model directory\n","model_path = \"/content/drive/MyDrive/Colab Notebooks/SIH- DOJ CHATBOT/Trained LLM model\"\n","\n","# Load model and tokenizer\n","model = GPT2LMHeadModel.from_pretrained(model_path)  # No safetensors keyword here\n","tokenizer = GPT2Tokenizer.from_pretrained(model_path)\n","\n","# Check if the model was loaded properly\n","print(model)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"id":"6PptUMHW3zml","executionInfo":{"status":"ok","timestamp":1732708076460,"user_tz":-330,"elapsed":882,"user":{"displayName":"Nancy Kaim","userId":"03700283372253325446"}},"outputId":"fe330633-b4e3-4a6f-b39d-680f5cbd054f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["GPT2LMHeadModel(\n","  (transformer): GPT2Model(\n","    (wte): Embedding(50260, 768)\n","    (wpe): Embedding(1024, 768)\n","    (drop): Dropout(p=0.1, inplace=False)\n","    (h): ModuleList(\n","      (0-11): 12 x GPT2Block(\n","        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (attn): GPT2SdpaAttention(\n","          (c_attn): Conv1D(nf=2304, nx=768)\n","          (c_proj): Conv1D(nf=768, nx=768)\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (mlp): GPT2MLP(\n","          (c_fc): Conv1D(nf=3072, nx=768)\n","          (c_proj): Conv1D(nf=768, nx=3072)\n","          (act): NewGELUActivation()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","    )\n","    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","  )\n","  (lm_head): Linear(in_features=768, out_features=50260, bias=False)\n",")\n"]}]},{"cell_type":"markdown","source":["# ***TESTING PRE TRAINED MODEL***"],"metadata":{"id":"AnrjrKtoMFcN"}},{"cell_type":"code","source":["from transformers import pipeline, GPT2Tokenizer, GPT2LMHeadModel\n","\n","# Load fine-tuned model and tokenizer\n","model_path = \"/content/drive/MyDrive/Colab Notebooks/SIH- DOJ CHATBOT/Trained LLM model\"  # Path to your fine-tuned model\n","tokenizer = GPT2Tokenizer.from_pretrained(model_path)\n","model = GPT2LMHeadModel.from_pretrained(model_path)\n","\n","# Define a pipeline for text generation\n","generator = pipeline(\"text-generation\", model=model, tokenizer=tokenizer, pad_token_id=tokenizer.eos_token_id)\n","\n","# Test Queries\n","def generate_response(query):\n","    input_text = f\"<|startoftext|> {query} |bot|\"\n","    output = generator(input_text, max_length=100, num_return_sequences=1)\n","    response = output[0]['generated_text'].split(\"|bot|\")[1].split(\"<|endoftext|>\")[0].strip()\n","    return response\n","\n","# Example Query\n","query = \"Can you explain what the Tele-Law service is?\"\n","response = generate_response(query)\n","print(f\"Query: {query}\")\n","print(f\"Response: {response}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cVfBrFGJ4E6l","executionInfo":{"status":"ok","timestamp":1733204561936,"user_tz":-330,"elapsed":16980,"user":{"displayName":"Nancy Kaim","userId":"03700283372253325446"}},"outputId":"156403f8-5602-4ce6-fa49-e0ddf975736b"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stderr","text":["Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"]},{"output_type":"stream","name":"stdout","text":["Query: Can you explain what the Tele-Law service is?\n","Response: It provides legal advice on domestic disputes involving domestic violence, public safety issues such as domestic terrorism, and financial matters. The service is available for free in over 20 cities around the country, providing free legal help and advice to domestic claimants, especially in cases involving child marriage, dowry, forced marriage, child marriage, and dowry fraud.\n"]}]},{"cell_type":"markdown","source":["# ***MAIN QUERY MODEL***\n"],"metadata":{"id":"4-RAsd9PF3WT"}},{"cell_type":"code","source":["import torch\n","from transformers import GPT2Tokenizer, GPT2LMHeadModel, Trainer, TrainingArguments\n","from datasets import load_dataset\n","\n","# Load the dataset directly\n","dataset = load_dataset(\"text\", data_files=\"/content/drive/MyDrive/Colab Notebooks/SIH- DOJ CHATBOT/Data/querydata.txt\", split=\"train\")  # Replace \"your_data.txt\" with your file name\n","\n","# Load tokenizer and model\n","tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n","model = GPT2LMHeadModel.from_pretrained(\"gpt2\")\n","\n","# Add special tokens\n","special_tokens = {\n","    'additional_special_tokens': ['<|startoftext|>', '|bot|', '<|endoftext|>']\n","}\n","tokenizer.add_special_tokens(special_tokens)\n","tokenizer.add_special_tokens({'pad_token': '[PAD]'})\n","model.resize_token_embeddings(len(tokenizer))\n","\n","# Tokenize the data\n","def tokenize_function(examples):\n","    return tokenizer(examples[\"text\"], truncation=True, padding=\"max_length\", max_length=512)\n","\n","tokenized_dataset = dataset.map(tokenize_function, batched=True, remove_columns=[\"text\"])\n","\n","# Data collator for dynamic padding\n","from transformers import DataCollatorForLanguageModeling\n","data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=False)\n","\n","# Training arguments\n","training_args = TrainingArguments(\n","    output_dir=\"/content/drive/MyDrive/Colab Notebooks/SIH- DOJ CHATBOT/Main Query Model\",\n","    overwrite_output_dir=True,\n","    num_train_epochs=3,\n","    per_device_train_batch_size=4,\n","    save_steps=500,\n","    save_total_limit=2,\n","    logging_dir=\"./logs\",\n","    logging_steps=10,\n","    learning_rate=5e-5,\n","    weight_decay=0.01,\n","    prediction_loss_only=True,\n","    evaluation_strategy=\"no\",\n","    report_to=\"none\"\n",")\n","\n","# Trainer setup\n","trainer = Trainer(\n","    model=model,\n","    args=training_args,\n","    train_dataset=tokenized_dataset,\n","    data_collator=data_collator,\n",")\n","\n","# Fine-tune the model\n","trainer.train()\n","\n","# Save the fine-tuned model\n","model.save_pretrained(\"/content/drive/MyDrive/Colab Notebooks/SIH- DOJ CHATBOT/Main Query Model\")\n","tokenizer.save_pretrained(\"/content/drive/MyDrive/Colab Notebooks/SIH- DOJ CHATBOT/Main Query Model\")\n","\n","# Testing the model (optional)\n","def generate_answer(question):\n","    input_text = f\"<|startoftext|> {question} |bot|\"\n","    inputs = tokenizer.encode(input_text, return_tensors=\"pt\")\n","    outputs = model.generate(inputs, max_length=100, pad_token_id=tokenizer.eos_token_id)\n","    response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n","    return response\n","\n","# Example\n","question = \"What are the number of cases registered as of January,2023?\"\n","print(generate_answer(question))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":596,"referenced_widgets":["71a3c7a933e64a32be8e334c05ba2685","f974368de7fe4556ac68b7a13c46e77b","1c18262e1cd3465c8c9770be83a9deb5","36f46ca5145e465b8da0e8f47d6c856b","16a610aee2da4042b248503984df34af","b14bada3eb0b475fb7e974ba4d9812c2","710f6f2dbffe4e36a69bf4a3a3b7c2a3","7329008240054a49a2f0a5040a808711","f5373dcd3804407e84b7585956da3385","5587d37dca1e4dc1b898975357157f2d","e972bfa5d84c45f695cefe212d79489c","a78feee26fb24cf397f732616b53a478","35556f0ff7cf4e27bf04bc05ee25ed94","24bb98e7ace948a58d5d6f04ed91f4d3","f74403a2f5944359870cf94d5fb81a69","6b7789af2b6a4fa296e2c0092008f06c","79c88ec4ea8d4a78a8cd347b6bb5ac73","3218d09867a4479e9eebb6a6c557f068","b86a7fcc774544cf8e7bb17f283dddf4","bdb5943deb7a4cd7bfc4275556e90064","502115fbd5d2415bbab4bac6a247186b","cd34113e29914259abe56c7ded202d0f","b33dd45adc1f47d199c87bf37e055443","ba9ee3a5398b4f1fb32f006032206bff","8394ee1c238e4e6c8ca1679f0ba282be","277f46c117a64e8eb80e1d77eb919cc7","f1cfec47a4bb4f9e8f142b6cb83dfd22","ad4f877b457a4a06a24c0404e5044704","2ee1d9cef21e442aba31ff8ed96f6765","2b0303ceb3504fd39753606fdef3e3fd","980f55a408bb4370a1b7f5a49cfa7176","3ebbce0d952b448092b49b5a4f2530f4","2e07d84df6bf466bb30e697af3b8bb28","ffee1dc877d544bfa770cc216278a954","6855611fa0034a6786cf10653c9342f1","66faec5e902d45fd91a5f69f785bdc62","97647a7d602043ef90893397cf5f4958","0e17e640077b42baaff6dde4e75869b3","28a70b4462ff497480b2d6ba4a47177e","d7a60bbb7efd4f67bcc627e830bc9b59","bfbaca0730e5418692784cb12c249bf2","213097a126a0468580933300c90fac75","5d1a6e216d7248b5b9d712b15bc7bbc4","5774de2068cf4b31a54275c73326c27b"]},"id":"qpDH4NWKGEmP","executionInfo":{"status":"ok","timestamp":1732706161624,"user_tz":-330,"elapsed":3574207,"user":{"displayName":"Nancy Kaim","userId":"03700283372253325446"}},"outputId":"dac64e71-7260-4e1c-bcae-3f827e775d19"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["Generating train split: 0 examples [00:00, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"71a3c7a933e64a32be8e334c05ba2685"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["model.safetensors:  61%|######1   | 336M/548M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a78feee26fb24cf397f732616b53a478"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b33dd45adc1f47d199c87bf37e055443"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`\n"]},{"output_type":"display_data","data":{"text/plain":["Map:   0%|          | 0/120 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ffee1dc877d544bfa770cc216278a954"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1568: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n","  warnings.warn(\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='90' max='90' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [90/90 58:09, Epoch 3/3]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>10</td>\n","      <td>4.466600</td>\n","    </tr>\n","    <tr>\n","      <td>20</td>\n","      <td>2.723000</td>\n","    </tr>\n","    <tr>\n","      <td>30</td>\n","      <td>2.774200</td>\n","    </tr>\n","    <tr>\n","      <td>40</td>\n","      <td>2.241500</td>\n","    </tr>\n","    <tr>\n","      <td>50</td>\n","      <td>2.217100</td>\n","    </tr>\n","    <tr>\n","      <td>60</td>\n","      <td>2.117400</td>\n","    </tr>\n","    <tr>\n","      <td>70</td>\n","      <td>1.953500</td>\n","    </tr>\n","    <tr>\n","      <td>80</td>\n","      <td>1.887600</td>\n","    </tr>\n","    <tr>\n","      <td>90</td>\n","      <td>1.864700</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"]},{"output_type":"stream","name":"stdout","text":[" What are the number of cases registered as of January,2023?  model1 \n"]}]},{"cell_type":"code","source":["from transformers import pipeline, GPT2Tokenizer, GPT2LMHeadModel\n","\n","# Load fine-tuned model and tokenizer\n","model_path = \"/content/drive/MyDrive/Colab Notebooks/SIH- DOJ CHATBOT/Main Query Model\"  # Path to your fine-tuned model\n","tokenizer = GPT2Tokenizer.from_pretrained(model_path)\n","model = GPT2LMHeadModel.from_pretrained(model_path)\n","\n","# Define a pipeline for text generation\n","generator = pipeline(\"text-generation\", model=model, tokenizer=tokenizer, pad_token_id=tokenizer.eos_token_id)\n","\n","# Test Queries\n","def generate_response(query):\n","    input_text = f\"<|startoftext|> {query} |bot|\"\n","    output = generator(input_text, max_length=100, num_return_sequences=1)\n","    response = output[0]['generated_text'].split(\"|bot|\")[1].split(\"<|endoftext|>\")[0].strip()\n","    return response\n","\n","# Example Query\n","query = \"What are total number of civil cases registered in 2016 India?\"\n","response = generate_response(query)\n","print(f\"Query: {query}\")\n","print(f\"Response: {response}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JOs4pdE0XWKR","executionInfo":{"status":"ok","timestamp":1733204604286,"user_tz":-330,"elapsed":9481,"user":{"displayName":"Nancy Kaim","userId":"03700283372253325446"}},"outputId":"664c686f-09a5-4b0a-eb9b-5a29bb7b53ef"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stderr","text":["Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"]},{"output_type":"stream","name":"stdout","text":["Query: What are total number of civil cases registered in 2016 India?\n","Response: model2\n"]}]}]}